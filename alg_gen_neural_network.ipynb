{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "def run_network(network):\n",
    "    nb_classes = 10\n",
    "    batch_size = 256\n",
    "    input_shape = (784,)\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.reshape(60000, 784)\n",
    "    x_test = x_test.reshape(10000, 784)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = to_categorical(y_train, nb_classes)\n",
    "    y_test = to_categorical(y_test, nb_classes)\n",
    "    \n",
    "    nb_layers = network['nb_layers']\n",
    "    nb_neurons = network['nb_neurons']\n",
    "    activation = network['activation']\n",
    "    optimizer = network['optimizer']\n",
    "    model = Sequential()\n",
    "    for layer in range(nb_layers):\n",
    "        if layer == 0:\n",
    "            model.add(Dense(nb_neurons, activation=activation, input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(Dense(nb_neurons, activation = activation))\n",
    "        model.add(Dropout(0.1))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=20,\n",
    "              verbose=0,\n",
    "              validation_data=(x_test, y_test))\n",
    "\n",
    "    #zbieranie wynikÃ³w\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from operator import add\n",
    "import random\n",
    "\n",
    "import random\n",
    "\n",
    "class Network():\n",
    "    def __init__(self, nn_param_choices=None):\n",
    "        self.accuracy = 0.\n",
    "        self.nn_param_choices = nn_param_choices\n",
    "        self.network = {}\n",
    "\n",
    "    def create_random(self):\n",
    "        for key in self.nn_param_choices:\n",
    "            self.network[key] = random.choice(self.nn_param_choices[key])\n",
    "\n",
    "    def create_set(self, network):\n",
    "        self.network = network\n",
    "\n",
    "    def train(self):\n",
    "        if self.accuracy == 0.:\n",
    "            self.accuracy = run_network(self.network)\n",
    "\n",
    "    def print_network(self):\n",
    "        print(self.network)\n",
    "        print(f'Network accuracy: {self.accuracy * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUTATE_CHANCE = 0.15\n",
    "RANDOM_SELECT = 0.15\n",
    "RETAIN = 0.5\n",
    "PARAMS = {\n",
    "    'nb_neurons': [16, 32, 64, 128, 256],\n",
    "    'nb_layers': [1, 2, 3],\n",
    "    'activation': ['relu', 'tanh','selu', 'sigmoid'],\n",
    "    'optimizer': ['adam', 'sgd', 'adadelta', 'adamax'],\n",
    "}\n",
    "\n",
    "def create_population(count):\n",
    "    pop = []\n",
    "    for _ in range(0, count):\n",
    "        network = Network(PARAMS)\n",
    "        network.create_random()\n",
    "        pop.append(network)\n",
    "    return pop\n",
    "\n",
    "def fitness(network):\n",
    "    return network.accuracy\n",
    "\n",
    "def grade(pop):\n",
    "    summed = reduce(add, (fitness(network) for network in pop))\n",
    "    return summed / float((len(pop))) \n",
    "\n",
    "def mutate(network):\n",
    "    mutation = random.choice(list(PARAMS.keys()))\n",
    "    network.network[mutation] = random.choice(PARAMS[mutation])\n",
    "    return network\n",
    "\n",
    "def cross(parent1, parent2):\n",
    "    children = []\n",
    "    for i in range(2):\n",
    "        child = {}\n",
    "        for param in PARAMS:\n",
    "            child[param] = random.choice(\n",
    "                [parent1.network[param], parent2.network[param]]\n",
    "            )\n",
    "\n",
    "        network = Network(PARAMS)\n",
    "        network.create_set(child)\n",
    "\n",
    "        if MUTATE_CHANCE > random.random():\n",
    "            network = mutate(network)\n",
    "\n",
    "        children.append(network)\n",
    "\n",
    "    return children\n",
    "\n",
    "def evolve(pop):\n",
    "    graded = [(fitness(network), network) for network in pop]\n",
    "\n",
    "    graded = [x[1] for x in sorted(graded, key=lambda x: x[0], reverse=True)]\n",
    "\n",
    "    retain_length = int(len(graded)*RETAIN)\n",
    "\n",
    "    parents = graded[:retain_length]\n",
    "\n",
    "    for individual in graded[retain_length:]:\n",
    "        if RANDOM_SELECT > random.random():\n",
    "            parents.append(individual)\n",
    "\n",
    "    parents_length = len(parents)\n",
    "    desired_length = len(pop) - parents_length\n",
    "    children = []\n",
    "\n",
    "    while len(children) < desired_length:\n",
    "        parent1 = random.randint(0, parents_length-1)\n",
    "        parent2 = random.randint(0, parents_length-1)\n",
    "\n",
    "        if parent1 != parent2:\n",
    "            parent1 = parents[parent1]\n",
    "            parent2 = parents[parent2]\n",
    "\n",
    "            descendants = cross(parent1, parent2)\n",
    "\n",
    "            for descendant in descendants:\n",
    "                if len(children) < desired_length:\n",
    "                    children.append(descendant)\n",
    "\n",
    "    parents.extend(children)\n",
    "\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_networks(networks):\n",
    "    print('_'*100)\n",
    "    for network in networks:\n",
    "        network.print_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_accuracy(networks):\n",
    "    total_accuracy = 0\n",
    "    for network in networks:\n",
    "        total_accuracy += network.accuracy\n",
    "\n",
    "    return total_accuracy / len(networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generations = 6\n",
    "population = 2\n",
    "\n",
    "print(f'Run with {generations} generations and {population} populations')\n",
    "\n",
    "networks = create_population(population)\n",
    "\n",
    "for i in range(generations):\n",
    "    print(f'Generartion {i+1}...')\n",
    "    for idx, network in enumerate(networks):\n",
    "        print(f'Network {idx}')\n",
    "        network.train()\n",
    "    average_accuracy = get_average_accuracy(networks)\n",
    "    print(f'Average for generation {i+1}: {average_accuracy * 100}%')\n",
    "\n",
    "    if i != generations - 1:\n",
    "        networks = evolve(networks)\n",
    "\n",
    "networks = sorted(networks, key=lambda x: x.accuracy, reverse=True)\n",
    "\n",
    "print_networks(networks[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np\n",
    "\n",
    "parameters = {'solver': ['adam', 'sgd', 'adadelta', 'adamax'], 'max_iter': [20],\n",
    "              'hidden_layer_sizes': [(16,), (32,), (64,), (128,), (256,), (16, 16,), (32, 32,), (64, 64,), (128, 128,), (256, 256,), (16, 16, 16,), (32, 32, 32,), (64, 64, 64,), (128, 128, 128,), (256, 256, 256,), ],\n",
    "                'batch_size': [256], 'activation':  ['relu', 'tanh','selu', 'sigmoid'], }\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "grid_search = GridSearchCV(MLPRegressor(), parameters,\n",
    "                           n_jobs=-1, verbose=1, cv=4)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print(grid_search.score(x_test, y_test))\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
